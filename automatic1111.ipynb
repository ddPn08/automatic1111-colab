{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ddPn08/automatic1111-colab/blob/main/automatic1111.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6OFCYOzNjDX"
      },
      "source": [
        "# [Stable Diffusion WebUI Colab](https://github.com/ddPn08/stable-diffusion-webui-colab) by [ddPn08](https://github.com/ddpn08/)\n",
        "\n",
        "This colab runs from the repo [`automatic1111`](https://github.com/AUTOMATIC1111/stable-diffusion-webui)  \n",
        "このColabは[`automatic1111`](https://github.com/AUTOMATIC1111/stable-diffusion-webui) を使用しています。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE45Pqn_N81E"
      },
      "source": [
        "## 1 - Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4xxtQfuJiWM"
      },
      "outputs": [],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cXkcQu6OEAu"
      },
      "source": [
        "### 1.1 Download repo and install\n",
        "\n",
        "Clone git repo and setup miniconda\n",
        "> Gitリポジトリをクローン、minicondaのセットアップ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzdbQDudNZ6j",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @markdown ## Clone the automatic1111/stable-diffusion-webui\n",
        "\n",
        "# Define a global variable\n",
        "ngrok_proc = None\n",
        "\n",
        "\n",
        "webui_branch = \"master\"  # @param {type: \"string\"}\n",
        "\n",
        "! git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
        "%cd stable-diffusion-webui\n",
        "! git checkout {webui_branch}\n",
        "\n",
        "import sys\n",
        "\n",
        "! curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "! chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "! bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "sys.path.append(\"/usr/local/lib/python3.8/site-packages/\")\n",
        "! rm Miniconda3-latest-Linux-x86_64.sh\n",
        "! conda env update -n base -f environment-wsl2.yaml\n",
        "\n",
        "! mkdir repositories\n",
        "! git clone https://github.com/CompVis/stable-diffusion.git repositories/stable-diffusion\n",
        "! git clone https://github.com/CompVis/taming-transformers.git repositories/taming-transformers\n",
        "! git clone https://github.com/sczhou/CodeFormer.git repositories/CodeFormer\n",
        "! git clone https://github.com/salesforce/BLIP.git repositories/BLIP\n",
        "\n",
        "! pip install transformers==4.19.2 diffusers invisible-watermark --prefer-binary\n",
        "! pip install git+https://github.com/crowsonkb/k-diffusion.git --prefer-binary\n",
        "! pip install git+https://github.com/TencentARC/GFPGAN.git --prefer-binary\n",
        "! pip install -r repositories/CodeFormer/requirements.txt --prefer-binary\n",
        "! pip install -r requirements.txt  --prefer-binary\n",
        "! pip install -U numpy  --prefer-binary\n",
        "\n",
        "! pip install pyngrok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOHgDng2c0FX"
      },
      "source": [
        "### 1.2 Setup models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Mls4_48XOrTd"
      },
      "outputs": [],
      "source": [
        "# @markdown # Load the stable-diffusion model\n",
        "# @markdown > ### stable-diffusionのモデルをロード\n",
        "\n",
        "# @markdown **Model Path Variables**\n",
        "# ask for the link\n",
        "print(\"Local Path Variables:\\n\")\n",
        "\n",
        "model_filename = \"sd-v1-4.ckpt\"  # @param {type:\"string\"}\n",
        "# @markdown First load the model specified by `model_filename`\n",
        "# @markdown > `model_filename`で指定したモデルをはじめにロードする\n",
        "specify_model = True # @param {type:\"boolean\"}\n",
        "models_path = \"/content/models\"  # @param {type:\"string\"}\n",
        "output_path = \"/content/output\"  # @param {type:\"string\"}\n",
        "config_path = \"/content/config\"  # @param {type:\"string\"}\n",
        "embeddings_path = \"/content/embeddings\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown **Download the model if it isn't already in the `models_path` folder (Optional)**\n",
        "# @markdown > モデルが`models_path`フォルダーにない場合に、モデルをダウンロードする\n",
        "\n",
        "# @markdown To download the model, you need to have accepted the terms [HERE](https://huggingface.co/CompVis/stable-diffusion-v1-4)\n",
        "# @markdown and have copied a token from [HERE](https://huggingface.co/settings/tokens)\n",
        "\n",
        "# @markdown > モデルをダウンロードするには, [このページ](https://huggingface.co/CompVis/stable-diffusion-v1-4)で条件に同意する必要があります。\n",
        "# @markdown > また、[このページ](https://huggingface.co/settings/tokens)からトークンを取得する必要があります。\n",
        "download_if_missing = False  # @param {type:\"boolean\"}\n",
        "model_url = \"https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt\"  # @param {type:\"string\"}\n",
        "token = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown **Google Drive Path Variables (Optional)**\n",
        "mount_google_drive = True  # @param {type:\"boolean\"}\n",
        "force_remount = False\n",
        "\n",
        "%cd /content/\n",
        "import os\n",
        "\n",
        "mount_success = True\n",
        "if mount_google_drive:\n",
        "    from google.colab import drive\n",
        "\n",
        "    try:\n",
        "        drive_path = \"/content/drive\"\n",
        "        drive.mount(drive_path, force_remount=force_remount)\n",
        "        models_path_gdrive = \"/content/drive/MyDrive/AI/models\"  # @param {type:\"string\"}\n",
        "        output_path_gdrive = \"/content/drive/MyDrive/AI/automatic1111/outputs\"  # @param {type:\"string\"}\n",
        "        config_path_gdrive = \"/content/drive/MyDrive/AI/automatic1111/config\"  # @param {type:\"string\"}\n",
        "        embeddings_path_gdrive = \"/content/drive/MyDrive/AI/textual-inversion/embeddings\"  # @param {type:\"string\"}\n",
        "        models_path = models_path_gdrive\n",
        "        output_path = output_path_gdrive\n",
        "        config_path = config_path_gdrive\n",
        "        embeddings_path = embeddings_path_gdrive\n",
        "    except:\n",
        "        print(\"...error mounting drive or with drive path variables\")\n",
        "        print(\"...reverting to default path variables\")\n",
        "        mount_success = False\n",
        "\n",
        "os.makedirs(models_path, exist_ok=True)\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "os.makedirs(config_path, exist_ok=True)\n",
        "os.makedirs(embeddings_path, exist_ok=True)\n",
        "\n",
        "if not os.path.exists(f\"{config_path}/config.json\"):\n",
        "    with open(f\"{config_path}/config.json\", mode=\"w\") as f:\n",
        "        f.write('{\"outdir_samples\": \"' + output_path + '\"}')\n",
        "\n",
        "if download_if_missing:\n",
        "    if not mount_success:\n",
        "        print(\"Downloading model to \" + models_path + \" due to gdrive mount error\")\n",
        "    elif not os.path.exists(models_path + \"/\" + model_filename):\n",
        "        ! mkdir sd-model\n",
        "        %cd /content/sd-model/\n",
        "        ! curl -LJ  {model_url} -o {model_filename} {'-H \"Authorization: Bearer ' + token + '\"' if token else \"\"}\n",
        "        ! mv /content/sd-model/{model_filename} {models_path}/\n",
        "        %cd /content/\n",
        "    else:\n",
        "        print(\"Model already downloaded, moving to next step\")\n",
        "\n",
        "print(f\"models_path: {models_path}\")\n",
        "print(f\"output_path: {output_path}\")\n",
        "print(f\"config_path: {config_path}\")\n",
        "print(f\"embeddings_path: {embeddings_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DzMlOhl0Rerq"
      },
      "outputs": [],
      "source": [
        "# @markdown ## Download GFPGAN model\n",
        "# @markdown **GFPGAN** Automatically correct distorted faces with a built-in GFPGAN option, fixes them in less than half a second\n",
        "# @markdown > **GFPGAN** オプションで歪んだ顔を自動的に修正し、0.5秒未満で修正します\n",
        "\n",
        "%cd stable-diffusion-webui\n",
        "! curl -LOJ https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JkrcrPBza-M"
      },
      "source": [
        "## 2 Optional - Set webUI settings and configs before running"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "goUvyTZ4zd4l"
      },
      "outputs": [],
      "source": [
        "# @markdown # Launch preferences - Advanced\n",
        "# @markdown # 詳細設定\n",
        "\n",
        "# @markdown Click here for more information -> https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Optimizations\n",
        "# @markdown > 詳しい情報はこちらから -> https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Optimizations\n",
        "\n",
        "no_half = False  # @param {type:\"boolean\"}\n",
        "# @markdown * Do not switch the model to 16-bit floats\n",
        "# @markdown > モデルを16ビットfloatに切り替えない\n",
        "no_progressbar_hiding = False  # @param {type:\"boolean\"}\n",
        "# @markdown * Do not hide progressbar in gradio UI (we hide it because it slows down ML if you have hardware acceleration in browser)\n",
        "# @markdown > プログレスバーを非表示にしない (ブラウザにハードウェアアクセラレーションが場合MLが遅くなるため非表示にすることを推奨します)\n",
        "medvram = False  # @param {type:\"boolean\"}\n",
        "# @markdown * Makes the Stable Diffusion model consume less VRAM by splitting it into three parts - cond (for transforming text into numerical representation), first_stage (for converting a picture into latent space and back), and unet (for actual denoising of latent space) and making it so that only one is in VRAM at all times, sending others to CPU RAM. Lowers performance, but only by a bit - except if live previews are enabled.\n",
        "# @markdown > Stable Diffusion モデルが VRAM の消費を少なくするために、cond(テキストを数値表現に変換するため)、first_stage(画像を潜在空間に変換して元に戻すため)、およびunet(潜在空間の実際のノイズ除去のため) の3つの部分に分割し、 常に1つだけがVRAMにあり、残りはCPU RAMに送信されるようにします。 (パフォーマンスが少し低下します。ライブプレビューが有効になっている場合さらに性能低下が大きくなります。)\n",
        "lowvram = False  # @param {type:\"boolean\"}\n",
        "# @markdown * An even more thorough optimization of the above, splitting unet into many modules, and only one module is kept in VRAM. Devastating for performance.\n",
        "# @markdown > `medvram`をさらに徹底的に最適化し、unetを多くのモジュールに分割し、1つのモジュールのみをVRAMに保持します。 パフォーマンスは壊滅的。\n",
        "disable_opt_split_attention = False  # @param {type:\"boolean\"}\n",
        "# @markdown * Force-disables cross-attention layer optimization.\n",
        "# @markdown > クロスアテンションレイヤーの最適化を強制的に無効にします。\n",
        "\n",
        "run_string_with_variables = {\n",
        "    \"--no-half\": f\"{no_half}\",\n",
        "    \"--no-progressbar-hiding\": f\"{no_progressbar_hiding}\",\n",
        "    \"--medvram\": f\"{medvram}\",\n",
        "    \"--lowvram\": f\"{lowvram}\",\n",
        "    \"--disable-opt-split-attention\": f\"{disable_opt_split_attention}\",\n",
        "}\n",
        "\n",
        "only_true_vars = {k for (k, v) in run_string_with_variables.items() if v == \"True\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htQtwGXHTaob"
      },
      "source": [
        "## 3 - Launch WebUI for stable diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Nfxj7FhHTVF8"
      },
      "outputs": [],
      "source": [
        "# @markdown # Start Ngrok Tunnel (Optional)\n",
        "# @markdown > Ngrokのトンネルを起動する (オプション)\n",
        "\n",
        "# @markdown Use Ngrok tunneling for more stable communication. To use this, you need to [sign up](https://ngrok.com/) for Ngrok and [get a token](https://dashboard.ngrok.com/get-started/setup).\n",
        "# @markdown > より安定した通信のために Ngrok トンネリングを使用します。 これを使用するには、Ngrok に[サインアップ]((https://ngrok.com/) して[トークンを取得](https://dashboard.ngrok.com/get-started/setup) する必要があります。\n",
        "\n",
        "use_ngrok = False  # @param {type: \"boolean\"}\n",
        "ngrok_auth_token = \"\"  # @param {type: \"string\"}\n",
        "ngrok_region = \"us\"  # @param [\"us\", \"eu\", \"au\", \"ap\", \"sa\", \"jp\", \"in\"]\n",
        "port = 7860  # @param {type: \"number\"}\n",
        "\n",
        "if use_ngrok:\n",
        "    from pyngrok import ngrok\n",
        "\n",
        "    if ngrok_proc:\n",
        "        ngrok_proc.proc.kill()\n",
        "    pyngrok_config = ngrok.conf.PyngrokConfig(\n",
        "        auth_token=ngrok_auth_token, region=ngrok_region\n",
        "    )\n",
        "    tunnel = ngrok.connect(f\"localhost:{port}\", pyngrok_config=pyngrok_config)\n",
        "    ngrok_proc = ngrok.get_ngrok_process()\n",
        "    print(tunnel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Y4ebYsPqTrGb"
      },
      "outputs": [],
      "source": [
        "#@markdown keep in mind that this script is set to run for ever.\n",
        "#@markdown > ※注意 このスクリプトは永久に実行されます。\n",
        "\n",
        "#@markdown # Important - click the public URL to launch WebUI in another tab\n",
        "#@markdown > ### 重要 - 公開URLをクリックしてWebUIを起動してください\n",
        "\n",
        "#@markdown ![](https://user-images.githubusercontent.com/71378929/189563599-6df78bcf-133b-41e8-a55d-8ca3783cd933.png)\n",
        "\n",
        "import os\n",
        "\n",
        "transformers_offline = False # @param {type: \"boolean\"}\n",
        "os.environ['TRANSFORMERS_OFFLINE'] = \"1\" if transformers_offline else \"0\"\n",
        "\n",
        "vars = \" \".join(only_true_vars)\n",
        "if not ngrok_proc:\n",
        "  vars += \" --share\"\n",
        "\n",
        "if specify_model:\n",
        "  vars += f\" --ckpt {models_path}/{model_filename}\"\n",
        "\n",
        "! git pull\n",
        "! python webui.py \\\n",
        "  --ckpt-dir {models_path} \\\n",
        "  --ui-config-file {config_path}/ui-config.json \\\n",
        "  --ui-settings-file {config_path}/config.json \\\n",
        "  --styles-file {config_path}/styles.csv \\\n",
        "  $vars"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "automatic1111-stable-diffusion-webui",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "a162c579ae611c46b3f917020f03078da6a8872353b51058912d08182f7284c9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}